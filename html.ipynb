{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'stem'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mUntitled-2.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m k \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m,\u001b[39m8\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcos(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mk\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mpi\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39;49mstem(k,x,use_line_collection\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Apoorva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\_api\\__init__.py:222\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m props:\n\u001b[0;32m    221\u001b[0m     \u001b[39mreturn\u001b[39;00m props[name]\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance)\n\u001b[1;32m--> 222\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    223\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'stem'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create 2D array of table given above\n",
    "data = [['E001', 'M', 34, 123, 'Normal', 350],\n",
    "        ['E002', 'F', 40, 114, 'Overweight', 450],\n",
    "        ['E003', 'F', 37, 135, 'Obesity', 169],\n",
    "        ['E004', 'M', 30, 139, 'Underweight', 189],\n",
    "        ['E005', 'F', 70, 117, 'Underweight', 183],\n",
    "        ['E006', 'M', 36, 121, 'Normal', 80],\n",
    "        ['E007', 'M', 32, 133, 'Obesity', 166],\n",
    "        ['E008', 'F', 26, 140, 'Normal', 120],\n",
    "        ['E009', 'M', 32, 133, 'Normal', 75],\n",
    "        ['E010', 'M', 36, 133, 'Underweight', 40] ]\n",
    "\n",
    "# dataframe created with\n",
    "# the above data array\n",
    "df = pd.DataFrame(data, columns = ['EMPID', 'Gender','Age', 'Sales','BMI', 'Income'] )\n",
    "\n",
    "# create histogram for numeric data\n",
    "df.hist()\n",
    "# show plot\n",
    "plt.show()\n",
    "\n",
    "sum=21.3+20.8+19\n",
    "mean = sum/3\n",
    "print(mean)\n",
    "20.366666666666667\n",
    "import statistics as st\n",
    "\n",
    "list1 =[1, 2, 3, 4]\n",
    "        #  2+3/2 is the median\n",
    "print(st.median(list1))\n",
    "2.5\n",
    "import statistics as st\n",
    "\n",
    "list1 =[2,3,7,4,2,6,4,7,7,4,7,2,4]       #  2+3/2 is the median\n",
    "print(st.mode(list1))\n",
    "7\n",
    "import statistics as st\n",
    "\n",
    "list1 =[2,3,7,4,2,6,4,7,7,4,7,2,4]       #  2+3/2 is the median\n",
    "max1 = max(list1)\n",
    "min1 = min(list1)\n",
    "range = max1  - min1\n",
    "print(range)\n",
    "5\n",
    "import statistics as st\n",
    "list1 =[2.75, 1.75, 1.25, 0.25, 0.5, 1.25, 3.5]\n",
    "print(st.variance(list1))\n",
    "1.3720238095238095\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "# create 2D array of table given above\n",
    "data = [['E001', 'M', 34, 123, 'Normal', 50],\n",
    "        ['E002', 'F', 40, 114, 'Overweight', 150],\n",
    "        ['E003', 'F', 37, 135, 'Obesity', 169],\n",
    "        ['E004', 'M', 30, 139, 'Underweight', 210],\n",
    "        ['E005', 'F', 44, 117, 'Underweight', 183],\n",
    "        ['E006', 'M', 36, 121, 'Normal', 80],\n",
    "        ['E007', 'M', 32, 133, 'Obesity', 166],\n",
    "        ['E008', 'F', 26, 140, 'Normal', 120],\n",
    "        ['E009', 'M', 32, 133, 'Normal', 75],\n",
    "        ['E010', 'M', 36, 133, 'Underweight', 40],\n",
    "        ['E011', 'M', 50, 153, 'Underweight', 123] ]\n",
    "\n",
    "# dataframe created with\n",
    "# the above data array\n",
    "df = pd.DataFrame(data, columns = ['EMPID', 'Gender','Age', 'Sales','BMI', 'Income'] )\n",
    "df.plot.bar()\n",
    "plt.show()\n",
    "plt.bar(df['Age'], df['Income'])\n",
    "plt.show()\n",
    "---------------------------------------------------------------------------\n",
    "ImportError                               Traceback (most recent call last)\n",
    "g:\\Backup Sep 2 2022\\Desk\\sample\\Module3\\practical.ipynb Cell 7 in <cell line: 2>()\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a> import pandas as pd\n",
    "----> <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a> import matplotlib.pyplot as plt\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a> # create 2D array of table given above\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a> data = [['E001', 'M', 34, 123, 'Normal', 50],\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>         ['E002', 'F', 40, 114, 'Overweight', 150],\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>         ['E003', 'F', 37, 135, 'Obesity', 169],\n",
    "   (...)\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>         ['E010', 'M', 36, 133, 'Underweight', 40],\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>         ['E011', 'M', 50, 153, 'Underweight', 123] ]\n",
    "\n",
    "File c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:57, in <module>\n",
    "     55 from matplotlib import docstring\n",
    "     56 from matplotlib.backend_bases import FigureCanvasBase, MouseButton\n",
    "---> 57 from matplotlib.figure import Figure, figaspect\n",
    "     58 from matplotlib.gridspec import GridSpec, SubplotSpec\n",
    "     59 from matplotlib import rcParams, rcParamsDefault, get_backend, rcParamsOrig\n",
    "\n",
    "File c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:26, in <module>\n",
    "     24 import matplotlib as mpl\n",
    "     25 from matplotlib import _blocking_input, docstring, projections\n",
    "---> 26 from matplotlib.artist import (\n",
    "     27     Artist, allow_rasterization, _finalize_rasterization)\n",
    "     28 from matplotlib.backend_bases import (\n",
    "     29     FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
    "     30 import matplotlib._api as _api\n",
    "\n",
    "ImportError: cannot import name '_finalize_rasterization' from 'matplotlib.artist' (c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py)\n",
    "from turtle import color\n",
    "\n",
    "\n",
    "data = [['E001', 'M', 34, 123, 'Normal', 50],\n",
    "        ['E002', 'F', 40, 114, 'Overweight', 150],\n",
    "        ['E003', 'F', 37, 135, 'Obesity', 169],\n",
    "        ['E004', 'M', 30, 139, 'Underweight', 210],\n",
    "        ['E005', 'F', 44, 117, 'Underweight', 183],\n",
    "        ['E006', 'M', 36, 121, 'Normal', 80],\n",
    "        ['E007', 'M', 32, 133, 'Obesity', 166],\n",
    "        ['E008', 'F', 26, 140, 'Normal', 120],\n",
    "        ['E009', 'M', 32, 133, 'Normal', 75],\n",
    "        ['E010', 'M', 36, 133, 'Underweight', 51] ]\n",
    "df = pd.DataFrame(data, columns = ['EMPID', 'Gender','Age', 'Sales','BMI', 'Income'] )\n",
    "\n",
    "df.plot.box()\n",
    "plt.show()\n",
    "plt.boxplot(df['Age'])\n",
    "plt.title(' plot for sales persons',color='red')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = numpy.random.normal(0.0, 1.0, 10000)\n",
    "\n",
    "plt.hist(x, 100)\n",
    "plt.show()\n",
    "\n",
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    " \n",
    " \n",
    "# Create axis\n",
    "axes = [5, 5, 5]\n",
    " \n",
    "# Create Data\n",
    "data = np.ones(axes, dtype=np.bool)\n",
    " \n",
    "# Control Transparency\n",
    "alpha = 0.9\n",
    " \n",
    "# Control colour\n",
    "colors = np.empty(axes + [4], dtype=np.float32)\n",
    " \n",
    "colors[:] = [1, 1, 0, alpha]  # red\n",
    " \n",
    "# Plot figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    " \n",
    "# Voxels is used to customizations of the\n",
    "# sizes, positions and colors.\n",
    "ax.voxels(data, facecolors=colors)\n",
    "{(0, 0, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc840e80>,\n",
    " (0, 0, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc890250>,\n",
    " (0, 1, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc890c70>,\n",
    " (0, 1, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc890880>,\n",
    " (0, 2, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc8906d0>,\n",
    " (0, 2, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc890a30>,\n",
    " (0, 3, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc8714c0>,\n",
    " (0, 3, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc871ca0>,\n",
    " (0, 4, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc871820>,\n",
    " (0, 4, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc8713a0>,\n",
    " (1, 0, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc8719a0>,\n",
    " (1, 0, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc82d0a0>,\n",
    " (1, 1, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc82d4f0>,\n",
    " (1, 1, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc82d610>,\n",
    " (1, 2, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc82df10>,\n",
    " (1, 2, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc82d6a0>,\n",
    " (1, 3, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc82d130>,\n",
    " (1, 3, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc86bfd0>,\n",
    " (1, 4, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc86b8e0>,\n",
    " (1, 4, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc86b4c0>,\n",
    " (2, 0, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc86b3d0>,\n",
    " (2, 0, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc877ca0>,\n",
    " (2, 1, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc877d60>,\n",
    " (2, 1, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc877c10>,\n",
    " (2, 2, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc877760>,\n",
    " (2, 2, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc877490>,\n",
    " (2, 3, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc8774c0>,\n",
    " (2, 3, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc88cdc0>,\n",
    " (2, 4, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc88c520>,\n",
    " (2, 4, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc88c3d0>,\n",
    " (3, 0, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc88cb50>,\n",
    " (3, 0, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc7d5f40>,\n",
    " (3, 1, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc7d5550>,\n",
    " (3, 1, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc7d5e80>,\n",
    " (3, 2, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc7d56d0>,\n",
    " (3, 2, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x9607400>,\n",
    " (3, 3, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6e1250>,\n",
    " (3, 3, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc67e820>,\n",
    " (3, 4, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc67ee80>,\n",
    " (3, 4, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc67efa0>,\n",
    " (4, 0, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc67e4f0>,\n",
    " (4, 0, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc67e190>,\n",
    " (4, 1, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6c4490>,\n",
    " (4, 1, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6c4a30>,\n",
    " (4, 2, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6c4340>,\n",
    " (4, 2, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6c4e20>,\n",
    " (4, 3, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6a9370>,\n",
    " (4, 3, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6a95b0>,\n",
    " (4, 4, 0): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6a9100>,\n",
    " (4, 4, 4): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6a9b50>,\n",
    " (0, 0, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6a9940>,\n",
    " (4, 0, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6b6910>,\n",
    " (0, 0, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6b6760>,\n",
    " (4, 0, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6b6d00>,\n",
    " (0, 0, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6b6370>,\n",
    " (4, 0, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6b6970>,\n",
    " (0, 1, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6bc0d0>,\n",
    " (4, 1, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6bcc40>,\n",
    " (0, 1, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6bc340>,\n",
    " (4, 1, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6bc310>,\n",
    " (0, 1, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6bcf70>,\n",
    " (4, 1, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc69bd90>,\n",
    " (0, 2, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc69b2e0>,\n",
    " (4, 2, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc69b730>,\n",
    " (0, 2, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc69bb50>,\n",
    " (4, 2, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc69b7f0>,\n",
    " (0, 2, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6d0f40>,\n",
    " (4, 2, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6d0850>,\n",
    " (0, 3, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6c8d60>,\n",
    " (4, 3, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6c8910>,\n",
    " (0, 3, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6c82b0>,\n",
    " (4, 3, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6c8eb0>,\n",
    " (0, 3, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6dc730>,\n",
    " (4, 3, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6dcb50>,\n",
    " (0, 4, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x9db4e50>,\n",
    " (4, 4, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5c6070>,\n",
    " (0, 4, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5c63d0>,\n",
    " (4, 4, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5c6b50>,\n",
    " (0, 4, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5c6c10>,\n",
    " (4, 4, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5c6fa0>,\n",
    " (1, 0, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5d64c0>,\n",
    " (1, 4, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5d66a0>,\n",
    " (2, 0, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5d6cd0>,\n",
    " (2, 4, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5d6d60>,\n",
    " (3, 0, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0x9cf4a90>,\n",
    " (3, 4, 1): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc64d430>,\n",
    " (1, 0, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc635130>,\n",
    " (1, 4, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc635310>,\n",
    " (2, 0, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc635c40>,\n",
    " (2, 4, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc635fa0>,\n",
    " (3, 0, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6356a0>,\n",
    " (3, 4, 2): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc635e50>,\n",
    " (1, 0, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5a5640>,\n",
    " (1, 4, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5a5ee0>,\n",
    " (2, 0, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5a58b0>,\n",
    " (2, 4, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5a5c40>,\n",
    " (3, 0, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc5a5160>,\n",
    " (3, 4, 3): <mpl_toolkits.mplot3d.art3d.Poly3DCollection at 0xc6220a0>}\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as nplot\n",
    "nplot.style.use(\"seaborn-whitegrid\")\n",
    "time =np.arange(0,12.5,0.1)\n",
    "amp= np.sin(time)\n",
    "nplot.plot(time,amp)\n",
    "\n",
    "amp= np.cos(time)\n",
    "nplot.plot(time,amp)\n",
    "nplot.show()\n",
    "\n",
    "plt.pie(df['Age'], labels = {\"Emp1\", \"Emp1\", \"C\",\"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"},\n",
    "autopct ='% 1.1f %%', shadow = True)\n",
    "plt.show()\n",
    "plt.pie(df['Income'], labels = {\"A\", \"B\", \"C\", \"D\", \"E\", \"F\",\"G\", \"H\", \"I\", \"J\"},\n",
    "autopct ='% 1.1f %%', shadow = True)\n",
    "plt.show()\n",
    "plt.pie(df['Sales'], labels = {\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"},\n",
    "autopct ='% 1.1f %%', shadow = True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "data = [['E001', 'M', 34, 123, 'Normal', 50],\n",
    "        ['E001', 'M', 35, 123, 'Normal', 52],\n",
    "        ['E0012', 'M', 36, 123, 'Normal', 49],\n",
    "        ['E0013', 'M', 37, 123, 'Normal', 54],\n",
    "        ['E002', 'F', 40, 114, 'Overweight', 150],\n",
    "        ['E003', 'F', 37, 135, 'Obesity', 169],\n",
    "        ['E004', 'M', 30, 139, 'Underweight', 210],\n",
    "        ['E005', 'F', 44, 117, 'Underweight', 183],\n",
    "        ['E006', 'M', 36, 121, 'Normal', 80],\n",
    "        ['E007', 'M', 32, 133, 'Obesity', 166],\n",
    "        ['E008', 'F', 26, 140, 'Normal', 120],\n",
    "        ['E009', 'M', 32, 133, 'Normal', 75],\n",
    "        ['E010', 'M', 36, 133, 'Underweight', 40] ]\n",
    "df = pd.DataFrame(data, columns = ['EMPID', 'Gender','Age', 'Sales','BMI', 'Income'] )\n",
    "\n",
    "plt.scatter(df['Income'],df['Age'])\n",
    "plt.show()\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline \n",
    "k = np.arange(0,8) \n",
    "x = np.cos(2*k*np.pi/4) \n",
    "plt.stem(k,x,use_line_collection=True) \n",
    "<StemContainer object of 3 artists>\n",
    "\n",
    "vec = np.array([[-2],[-2]])\n",
    "origin=np.zeros(vec.shape)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.quiver(*origin, *vec, color=['g'],scale=0.8,units='xy')\n",
    "plt.grid()\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()\n",
    "\n",
    "vec = np.array([[-3],[2]])\n",
    "origin=np.zeros(vec.shape)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.quiver(*origin, *vec, color=['b'],scale=1,units='xy')\n",
    "\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.grid()\n",
    "plt.gca().set_aspect('equal')\n",
    "# plt.show()\n",
    "\n",
    "theta = np.radians(-90)\n",
    "R = np.zeros((2,2))\n",
    "R[0,0]=np.cos(theta)\n",
    "R[0,1]=-np.sin(theta)\n",
    "R[1,0]=np.sin(theta)\n",
    "R[1,1]=np.cos(theta)\n",
    "print(R)\n",
    "\n",
    "new = np.zeros(vec.shape)\n",
    "new[0] = R[1,1]*vec[0] + R[0,1]*vec[1]\n",
    "new[0] = R[1,0]*vec[0] + R[0,0]*vec[1]\n",
    "new =R.dot(vec)\n",
    "\n",
    "origin = np.zeros(new.shape)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.quiver(*origin,*new, color=['r'],scale=1,units='xy')\n",
    "plt.grid()\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)\n",
    "plt.grid()\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()\n",
    "[[ 6.123234e-17  1.000000e+00]\n",
    " [-1.000000e+00  6.123234e-17]]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats.contingency import margins\n",
    "\n",
    "join_probability_X_Y = np.array([\n",
    "                [0.01, 0.02, 0.04, 0.04],\n",
    "                [0.03, 0.24, 0.15, 0.06],\n",
    "                [0.04, 0.10, 0.08, 0.08],\n",
    "                [0.02, 0.04, 0.03, 0.02]\n",
    "            ])\n",
    "\n",
    "\n",
    "x, y = margins(join_probability_X_Y)\n",
    "\n",
    "print(x.T)\n",
    "print(y.T)\n",
    "[[0.11 0.48 0.3  0.11]]\n",
    "[[0.1]\n",
    " [0.4]\n",
    " [0.3]\n",
    " [0.2]]\n",
    "# imports specific to the plots in this example\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import plt\n",
    "from mpl_toolkits.mplot3d.axes3d import get_test_data\n",
    "# Twice as wide as it is tall.\n",
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "#---- First subplot\n",
    "# Note that the declaration \"projection='3d'\"\n",
    "# is required for 3d plots!\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "# Generate the grid\n",
    "X = np.arange(-5, 5, 0.1)\n",
    "Y = np.arange(-5, 5, 0.1)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "# Generate the surface data\n",
    "R = np.sqrt(X**2+Y**2)\n",
    "Z = np.sin(R)\n",
    "# Plot the surface\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "cmap=cm.GnBu, linewidth=0, antialiased=False)\n",
    "ax.set_zlim3d(-1.01, 1.01)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)\n",
    "#---- Second subplot\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "X, Y, Z = get_test_data(0.05)\n",
    "ax.plot_wireframe(X, Y, Z, rstride=10, cstride=10)\n",
    "outfile = '3dGraph.png'\n",
    "plt.savefig(outfile, dpi=200)\n",
    "print('Image saved to {0}'.format(outfile))\n",
    "plt.show()\n",
    "---------------------------------------------------------------------------\n",
    "ImportError                               Traceback (most recent call last)\n",
    "g:\\Backup Sep 2 2022\\Desk\\sample\\Module3\\practical.ipynb Cell 18 in <cell line: 4>()\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a> import numpy as np\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a> from matplotlib import cm\n",
    "----> <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a> from matplotlib.pyplot import plt\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a> from mpl_toolkits.mplot3d.axes3d import get_test_data\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a> # Twice as wide as it is tall.\n",
    "\n",
    "File c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:57, in <module>\n",
    "     55 from matplotlib import docstring\n",
    "     56 from matplotlib.backend_bases import FigureCanvasBase, MouseButton\n",
    "---> 57 from matplotlib.figure import Figure, figaspect\n",
    "     58 from matplotlib.gridspec import GridSpec, SubplotSpec\n",
    "     59 from matplotlib import rcParams, rcParamsDefault, get_backend, rcParamsOrig\n",
    "\n",
    "File c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:26, in <module>\n",
    "     24 import matplotlib as mpl\n",
    "     25 from matplotlib import _blocking_input, docstring, projections\n",
    "---> 26 from matplotlib.artist import (\n",
    "     27     Artist, allow_rasterization, _finalize_rasterization)\n",
    "     28 from matplotlib.backend_bases import (\n",
    "     29     FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
    "     30 import matplotlib._api as _api\n",
    "\n",
    "ImportError: cannot import name '_finalize_rasterization' from 'matplotlib.artist' (c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py)\n",
    "from tkinter import PROJECTING\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig= plt.figure()\n",
    "\n",
    "ax = plt.axes(PROJECTING='3d')\n",
    "---------------------------------------------------------------------------\n",
    "ImportError                               Traceback (most recent call last)\n",
    "g:\\Backup Sep 2 2022\\Desk\\sample\\Module3\\practical.ipynb Cell 19 in <cell line: 3>()\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a> from tkinter import PROJECTING\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a> import numpy as np\n",
    "----> <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a> import matplotlib.pyplot as plt\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a> fig= plt.figure()\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a> ax = plt.axes(PROJECTING='3d')\n",
    "\n",
    "File c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:57, in <module>\n",
    "     55 from matplotlib import docstring\n",
    "     56 from matplotlib.backend_bases import FigureCanvasBase, MouseButton\n",
    "---> 57 from matplotlib.figure import Figure, figaspect\n",
    "     58 from matplotlib.gridspec import GridSpec, SubplotSpec\n",
    "     59 from matplotlib import rcParams, rcParamsDefault, get_backend, rcParamsOrig\n",
    "\n",
    "File c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:26, in <module>\n",
    "     24 import matplotlib as mpl\n",
    "     25 from matplotlib import _blocking_input, docstring, projections\n",
    "---> 26 from matplotlib.artist import (\n",
    "     27     Artist, allow_rasterization, _finalize_rasterization)\n",
    "     28 from matplotlib.backend_bases import (\n",
    "     29     FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
    "     30 import matplotlib._api as _api\n",
    "\n",
    "ImportError: cannot import name '_finalize_rasterization' from 'matplotlib.artist' (c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py)\n",
    "# importing mplot3d toolkits, numpy and matplotlib\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "fig = plt.figure()\n",
    " \n",
    "# syntax for 3-D projection\n",
    "ax = plt.axes(projection ='3d')\n",
    " \n",
    "# defining all 3 axes\n",
    "z = np.linspace(0, 1, 100)\n",
    "x = z * np.sin(25 * z)\n",
    "y = z * np.cos(25 * z)\n",
    " \n",
    "# plotting\n",
    "ax.plot3D(x, y, z, 'green')\n",
    "ax.set_title('3D line plot geeks for geeks')\n",
    "plt.show()\n",
    "---------------------------------------------------------------------------\n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "g:\\Backup Sep 2 2022\\Desk\\sample\\Module3\\practical.ipynb Cell 20 in <cell line: 4>()\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a> from mpl_toolkits import mplot3d\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a> import numpy as np\n",
    "----> <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a> import matplotlib.pyplot as plt\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a> fig = plt.figure()\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a> # syntax for 3-D projection\n",
    "\n",
    "ModuleNotFoundError: No module named 'matplotlib.pyplot'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "squares = [1, 4, 9, 16, 25]\n",
    "plt.plot(squares)\n",
    "plt.show()\n",
    "---------------------------------------------------------------------------\n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "g:\\Backup Sep 2 2022\\Desk\\sample\\Module3\\practical.ipynb Cell 21 in <cell line: 1>()\n",
    "----> <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a> import matplotlib.pyplot as plt\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a> squares = [1, 4, 9, 16, 25]\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a> plt.plot(squares)\n",
    "\n",
    "ModuleNotFoundError: No module named 'matplotlib.pyplot'\n",
    "from scipy import stats\n",
    "\n",
    "bernoulliDist = stats.bernoulli(0.5)\n",
    "p_tails =bernoulliDist.pmf(0)\n",
    "p_heads =bernoulliDist.pmf(1)\n",
    "\n",
    "trials = bernoulliDist.rvs(10)\n",
    "trials\n",
    "array([1, 1, 0, 1, 1, 1, 0, 0, 1, 0])\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "(p,num )=(0.5,4)\n",
    "\n",
    "binomDist = stats.binom(num,p)\n",
    "binomDist.pmf(np.arange(5))\n",
    "array([0.0625, 0.25  , 0.375 , 0.25  , 0.0625])\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "mu = -2\n",
    "sigma = 1.0\n",
    "\n",
    "myDistribution = stats.norm(mu,sigma)\n",
    "significanceLevel = 0.05\n",
    "\n",
    "myDistribution.ppf([significanceLevel/2, 1-significanceLevel/2])\n",
    "array([-1.95996398,  1.95996398])\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(100)\n",
    "y = 150 + 3*x + 0.03*x**2+5*np.random.randn(len(x))\n",
    "\n",
    "# Create the Design Matrices for the linear, quadratic,\n",
    "# and cubic fit\n",
    "M1 = np.vstack( (np.ones_like(x), x) ).T\n",
    "M2 = np.vstack( (np.ones_like(x), x, x**2) ).T\n",
    "M3 = np.vstack( (np.ones_like(x), x, x**2, x**3) ).T\n",
    "\n",
    "# an equivalent alternative solution with statsmodels would be\n",
    "# M1 = sm.add_constant(x)\n",
    "\n",
    "# Solve the equations\n",
    "p1 = np.linalg.lstsq(M1, y)\n",
    "p2 = np.linalg.lstsq(M2, y)\n",
    "p3 = np.linalg.lstsq(M3, y)\n",
    " \n",
    "np.set_printoptions(precision=3)\n",
    "print('The coefficients from the linear fit: {0}'.format(p1[0]))\n",
    "\n",
    "print('The coefficients from the quadratic fit: {0}'  .format(p2[0]))\n",
    "print('The coefficients from the cubic fit: {0}'  .format(p3[0]))\n",
    "---------------------------------------------------------------------------\n",
    "ImportError                               Traceback (most recent call last)\n",
    "g:\\Backup Sep 2 2022\\Desk\\sample\\Module3\\practical.ipynb Cell 25 in <cell line: 2>()\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a> import numpy as np\n",
    "----> <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a> import matplotlib.pyplot as plt\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a> x = np.arange(100)\n",
    "      <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a> y = 150 + 3*x + 0.03*x**2+5*np.random.randn(len(x))\n",
    "\n",
    "File c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:57, in <module>\n",
    "     55 from matplotlib import docstring\n",
    "     56 from matplotlib.backend_bases import FigureCanvasBase, MouseButton\n",
    "---> 57 from matplotlib.figure import Figure, figaspect\n",
    "     58 from matplotlib.gridspec import GridSpec, SubplotSpec\n",
    "     59 from matplotlib import rcParams, rcParamsDefault, get_backend, rcParamsOrig\n",
    "\n",
    "File c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:26, in <module>\n",
    "     24 import matplotlib as mpl\n",
    "     25 from matplotlib import _blocking_input, docstring, projections\n",
    "---> 26 from matplotlib.artist import (\n",
    "     27     Artist, allow_rasterization, _finalize_rasterization)\n",
    "     28 from matplotlib.backend_bases import (\n",
    "     29     FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
    "     30 import matplotlib._api as _api\n",
    "\n",
    "ImportError: cannot import name '_finalize_rasterization' from 'matplotlib.artist' (c:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py)\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from time import time\n",
    "\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\",\n",
    "]\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n",
    "\n",
    "\n",
    "def load_dataset(verbose=False, remove=()):\n",
    "    \"\"\"Load and vectorize the 20 newsgroups dataset.\"\"\"\n",
    "\n",
    "    data_train = fetch_20newsgroups(\n",
    "        subset=\"train\",\n",
    "        categories=categories,\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        remove=remove,\n",
    "    )\n",
    "\n",
    "    data_test = fetch_20newsgroups(\n",
    "        subset=\"test\",\n",
    "        categories=categories,\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        remove=remove,\n",
    "    )\n",
    "\n",
    "    # order of labels in `target_names` can be different from `categories`\n",
    "    target_names = data_train.target_names\n",
    "\n",
    "    # split target in a training set and a test set\n",
    "    y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "    # Extracting features from the training data using a sparse vectorizer\n",
    "    t0 = time()\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\"\n",
    "    )\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "    duration_train = time() - t0\n",
    "\n",
    "    # Extracting features from the test data using the same vectorizer\n",
    "    t0 = time()\n",
    "    X_test = vectorizer.transform(data_test.data)\n",
    "    duration_test = time() - t0\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    if verbose:\n",
    "\n",
    "        # compute size of loaded data\n",
    "        data_train_size_mb = size_mb(data_train.data)\n",
    "        data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "        print(\n",
    "            f\"{len(data_train.data)} documents - \"\n",
    "            f\"{data_train_size_mb:.2f}MB (training set)\"\n",
    "        )\n",
    "        print(f\"{len(data_test.data)} documents - {data_test_size_mb:.2f}MB (test set)\")\n",
    "        print(f\"{len(target_names)} categories\")\n",
    "        print(\n",
    "            f\"vectorize training done in {duration_train:.3f}s \"\n",
    "            f\"at {data_train_size_mb / duration_train:.3f}MB/s\"\n",
    "        )\n",
    "        print(f\"n_samples: {X_train.shape[0]}, n_features: {X_train.shape[1]}\")\n",
    "        print(\n",
    "            f\"vectorize testing done in {duration_test:.3f}s \"\n",
    "            f\"at {data_test_size_mb / duration_test:.3f}MB/s\"\n",
    "        )\n",
    "        print(f\"n_samples: {X_test.shape[0]}, n_features: {X_test.shape[1]}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, feature_names, target_names\n",
    "\n",
    "\n",
    "# %%\n",
    "# Analysis of a bag-of-words document classifier\n",
    "# ==============================================\n",
    "#\n",
    "# We will now train a classifier twice, once on the text samples including\n",
    "# metadata and once after stripping the metadata. For both cases we will analyze\n",
    "# the classification errors on a test set using a confusion matrix and inspect\n",
    "# the coefficients that define the classification function of the trained\n",
    "# models.\n",
    "#\n",
    "# Model without metadata stripping\n",
    "# --------------------------------\n",
    "#\n",
    "# We start by using the custom function `load_dataset` to load the data without\n",
    "# metadata stripping.\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_names, target_names = load_dataset(\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Our first model is an instance of the\n",
    "# :class:`~sklearn.linear_model.RidgeClassifier` class. This is a linear\n",
    "# classification model that uses the mean squared error on {-1, 1} encoded\n",
    "# targets, one for each possible class. Contrary to\n",
    "# :class:`~sklearn.linear_model.LogisticRegression`,\n",
    "# :class:`~sklearn.linear_model.RidgeClassifier` does not\n",
    "# provide probabilistic predictions (no `predict_proba` method),\n",
    "# but it is often faster to train.\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# %%\n",
    "# We plot the confusion matrix of this classifier to find if there is a pattern\n",
    "# in the classification errors.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred, ax=ax)\n",
    "ax.xaxis.set_ticklabels(target_names)\n",
    "ax.yaxis.set_ticklabels(target_names)\n",
    "_ = ax.set_title(\n",
    "    f\"Confusion Matrix for {clf.__class__.__name__}\\non the original documents\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "# The confusion matrix highlights that documents of the `alt.atheism` class are\n",
    "# often confused with documents with the class `talk.religion.misc` class and\n",
    "# vice-versa which is expected since the topics are semantically related.\n",
    "#\n",
    "# We also observe that some documents of the `sci.space` class can be misclassified as\n",
    "# `comp.graphics` while the converse is much rarer. A manual inspection of those\n",
    "# badly classified documents would be required to get some insights on this\n",
    "# asymmetry. It could be the case that the vocabulary of the space topic could\n",
    "# be more specific than the vocabulary for computer graphics.\n",
    "#\n",
    "# We can gain a deeper understanding of how this classifier makes its decisions\n",
    "# by looking at the words with the highest average feature effects:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_feature_effects():\n",
    "    # learned coefficients weighted by frequency of appearance\n",
    "    average_feature_effects = clf.coef_ * np.asarray(X_train.mean(axis=0)).ravel()\n",
    "\n",
    "    for i, label in enumerate(target_names):\n",
    "        top5 = np.argsort(average_feature_effects[i])[-5:][::-1]\n",
    "        if i == 0:\n",
    "            top = pd.DataFrame(feature_names[top5], columns=[label])\n",
    "            top_indices = top5\n",
    "        else:\n",
    "            top[label] = feature_names[top5]\n",
    "            top_indices = np.concatenate((top_indices, top5), axis=None)\n",
    "    top_indices = np.unique(top_indices)\n",
    "    predictive_words = feature_names[top_indices]\n",
    "\n",
    "    # plot feature effects\n",
    "    bar_size = 0.25\n",
    "    padding = 0.75\n",
    "    y_locs = np.arange(len(top_indices)) * (4 * bar_size + padding)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    for i, label in enumerate(target_names):\n",
    "        ax.barh(\n",
    "            y_locs + (i - 2) * bar_size,\n",
    "            average_feature_effects[i, top_indices],\n",
    "            height=bar_size,\n",
    "            label=label,\n",
    "        )\n",
    "    ax.set(\n",
    "        yticks=y_locs,\n",
    "        yticklabels=predictive_words,\n",
    "        ylim=[\n",
    "            0 - 4 * bar_size,\n",
    "            len(top_indices) * (4 * bar_size + padding) - 4 * bar_size,\n",
    "        ],\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    print(\"top 5 keywords per class:\")\n",
    "    print(top)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "_ = plot_feature_effects().set_title(\"Average feature effect on the original data\")\n",
    "\n",
    "# %%\n",
    "# We can observe that the most predictive words are often strongly positively\n",
    "# associated with a single class and negatively associated with all the other\n",
    "# classes. Most of those positive associations are quite easy to interpret.\n",
    "# However, some words such as `\"god\"` and `\"people\"` are positively associated to\n",
    "# both `\"talk.misc.religion\"` and `\"alt.atheism\"` as those two classes expectedly\n",
    "# share some common vocabulary. Notice however that there are also words such as\n",
    "# `\"christian\"` and `\"morality\"` that are only positively associated with\n",
    "# `\"talk.misc.religion\"`. Furthermore, in this version of the dataset, the word\n",
    "# `\"caltech\"` is one of the top predictive features for atheism due to pollution\n",
    "# in the dataset coming from some sort of metadata such as the email addresses\n",
    "# of the sender of previous emails in the discussion as can be seen below:\n",
    "\n",
    "data_train = fetch_20newsgroups(\n",
    "    subset=\"train\", categories=categories, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "for doc in data_train.data:\n",
    "    if \"caltech\" in doc:\n",
    "        print(doc)\n",
    "        break\n",
    "\n",
    "# %%\n",
    "# Such headers, signature footers (and quoted metadata from previous messages)\n",
    "# can be considered side information that artificially reveals the newsgroup by\n",
    "# identifying the registered members and one would rather want our text\n",
    "# classifier to only learn from the \"main content\" of each text document instead\n",
    "# of relying on the leaked identity of the writers.\n",
    "#\n",
    "# Model with metadata stripping\n",
    "# -----------------------------\n",
    "#\n",
    "# The `remove` option of the 20 newsgroups dataset loader in scikit-learn allows\n",
    "# to heuristically attempt to filter out some of this unwanted metadata that\n",
    "# makes the classification problem artificially easier. Be aware that such\n",
    "# filtering of the text contents is far from perfect.\n",
    "#\n",
    "# Let us try to leverage this option to train a text classifier that does not\n",
    "# rely too much on this kind of metadata to make its decisions:\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    feature_names,\n",
    "    target_names,\n",
    ") = load_dataset(remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "\n",
    "clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred, ax=ax)\n",
    "ax.xaxis.set_ticklabels(target_names)\n",
    "ax.yaxis.set_ticklabels(target_names)\n",
    "_ = ax.set_title(\n",
    "    f\"Confusion Matrix for {clf.__class__.__name__}\\non filtered documents\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "# By looking at the confusion matrix, it is more evident that the scores of the\n",
    "# model trained with metadata were over-optimistic. The classification problem\n",
    "# without access to the metadata is less accurate but more representative of the\n",
    "# intended text classification problem.\n",
    "\n",
    "_ = plot_feature_effects().set_title(\"Average feature effects on filtered documents\")\n",
    "\n",
    "# %%\n",
    "# In the next section we keep the dataset without metadata to compare several\n",
    "# classifiers.\n",
    "\n",
    "# %%\n",
    "# Benchmarking classifiers\n",
    "# ========================\n",
    "#\n",
    "# Scikit-learn provides many different kinds of classification algorithms. In\n",
    "# this section we will train a selection of those classifiers on the same text\n",
    "# classification problem and measure both their generalization performance\n",
    "# (accuracy on the test set) and their computation performance (speed), both at\n",
    "# training time and testing time. For such purpose we define the following\n",
    "# benchmarking utilities:\n",
    "\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def benchmark(clf, custom_name=False):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(f\"train time: {train_time:.3}s\")\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(f\"test time:  {test_time:.3}s\")\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(f\"accuracy:   {score:.3}\")\n",
    "\n",
    "    if hasattr(clf, \"coef_\"):\n",
    "        print(f\"dimensionality: {clf.coef_.shape[1]}\")\n",
    "        print(f\"density: {density(clf.coef_)}\")\n",
    "        print()\n",
    "\n",
    "    print()\n",
    "    if custom_name:\n",
    "        clf_descr = str(custom_name)\n",
    "    else:\n",
    "        clf_descr = clf.__class__.__name__\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "# %%\n",
    "# We now train and test the datasets with 8 different classification models and\n",
    "# get performance results for each model. The goal of this study is to highlight\n",
    "# the computation/accuracy tradeoffs of different types of classifiers for\n",
    "# such a multi-class text classification problem.\n",
    "#\n",
    "# Notice that the most important hyperparameters values were tuned using a grid\n",
    "# search procedure not shown in this notebook for the sake of simplicity.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "    (LogisticRegression(C=5, max_iter=1000), \"Logistic Regression\"),\n",
    "    (RidgeClassifier(alpha=1.0, solver=\"sparse_cg\"), \"Ridge Classifier\"),\n",
    "    (KNeighborsClassifier(n_neighbors=100), \"kNN\"),\n",
    "    (RandomForestClassifier(), \"Random Forest\"),\n",
    "    # L2 penalty Linear SVC\n",
    "    (LinearSVC(C=0.1, dual=False, max_iter=1000), \"Linear SVC\"),\n",
    "    # L2 penalty Linear SGD\n",
    "    (\n",
    "        SGDClassifier(\n",
    "            loss=\"log_loss\", alpha=1e-4, n_iter_no_change=3, early_stopping=True\n",
    "        ),\n",
    "        \"log-loss SGD\",\n",
    "    ),\n",
    "    # NearestCentroid (aka Rocchio classifier)\n",
    "    (NearestCentroid(), \"NearestCentroid\"),\n",
    "    # Sparse naive Bayes classifier\n",
    "    (ComplementNB(alpha=0.1), \"Complement naive Bayes\"),\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf, name))\n",
    "\n",
    "# %%\n",
    "# Plot accuracy, training and test time of each classifier\n",
    "# ========================================================\n",
    "#\n",
    "# The scatter plots show the trade-off between the test accuracy and the\n",
    "# training and testing time of each classifier.\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time)\n",
    "test_time = np.array(test_time)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 8))\n",
    "ax1.scatter(score, training_time, s=60)\n",
    "ax1.set(\n",
    "    title=\"Score-training time trade-off\",\n",
    "    yscale=\"log\",\n",
    "    xlabel=\"test accuracy\",\n",
    "    ylabel=\"training time (s)\",\n",
    ")\n",
    "fig, ax2 = plt.subplots(figsize=(10, 8))\n",
    "ax2.scatter(score, test_time, s=60)\n",
    "ax2.set(\n",
    "    title=\"Score-test time trade-off\",\n",
    "    yscale=\"log\",\n",
    "    xlabel=\"test accuracy\",\n",
    "    ylabel=\"test time (s)\",\n",
    ")\n",
    "\n",
    "for i, txt in enumerate(clf_names):\n",
    "    ax1.annotate(txt, (score[i], training_time[i]))\n",
    "    ax2.annotate(txt, (score[i], test_time[i]))\n",
    "\n",
    "# %%\n",
    "# The naive Bayes model has the best trade-off between score and\n",
    "# training/testing time, while Random Forest is both slow to train, expensive to\n",
    "# predict and has a comparatively bad accuracy. This is expected: for\n",
    "# high-dimensional prediction problems, linear models are often better suited as\n",
    "# most problems become linearly separable when the feature space has 10,000\n",
    "# dimensions or more.\n",
    "#\n",
    "# The difference in training speed and accuracy of the linear models can be\n",
    "# explained by the choice of the loss function they optimize and the kind of\n",
    "# regularization they use. Be aware that some linear models with the same loss\n",
    "# but a different solver or regularization configuration may yield different\n",
    "# fitting times and test accuracy. We can observe on the second plot that once\n",
    "# trained, all linear models have approximately the same prediction speed which\n",
    "# is expected because they all implement the same prediction function.\n",
    "#\n",
    "# KNeighborsClassifier has a relatively low accuracy and has the highest testing\n",
    "# time. The long prediction time is also expected: for each prediction the model\n",
    "# has to compute the pairwise distances between the testing sample and each\n",
    "# document in the training set, which is computationally expensive. Furthermore,\n",
    "# the \"curse of dimensionality\" harms the ability of this model to yield\n",
    "# competitive accuracy in the high dimensional feature space of text\n",
    "# classification problems.\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "g:\\Backup Sep 2 2022\\Desk\\sample\\Module3\\practical.ipynb Cell 26 in <cell line: 99>()\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=79'>80</a>     return X_train, X_test, y_train, y_test, feature_names, target_names\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=82'>83</a> # %%\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=83'>84</a> # Analysis of a bag-of-words document classifier\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=84'>85</a> # ==============================================\n",
    "   (...)\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=95'>96</a> # We start by using the custom function `load_dataset` to load the data without\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=96'>97</a> # metadata stripping.\n",
    "---> <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=98'>99</a> X_train, X_test, y_train, y_test, feature_names, target_names = load_dataset(\n",
    "    <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=99'>100</a>     verbose=True\n",
    "    <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=100'>101</a> )\n",
    "    <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=102'>103</a> # %%\n",
    "    <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=103'>104</a> # Our first model is an instance of the\n",
    "    <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=104'>105</a> # :class:`~sklearn.linear_model.RidgeClassifier` class. This is a linear\n",
    "   (...)\n",
    "    <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=109'>110</a> # provide probabilistic predictions (no `predict_proba` method),\n",
    "    <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=110'>111</a> # but it is often faster to train.\n",
    "    <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=112'>113</a> from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "g:\\Backup Sep 2 2022\\Desk\\sample\\Module3\\practical.ipynb Cell 26 in load_dataset(verbose, remove)\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=51'>52</a> X_test = vectorizer.transform(data_test.data)\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=52'>53</a> duration_test = time() - t0\n",
    "---> <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=54'>55</a> feature_names = vectorizer.get_feature_names_out()\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=56'>57</a> if verbose:\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=57'>58</a> \n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=58'>59</a>     # compute size of loaded data\n",
    "     <a href='vscode-notebook-cell:/g%3A/Backup%20Sep%202%202022/Desk/sample/Module3/practical.ipynb#X34sZmlsZQ%3D%3D?line=59'>60</a>     data_train_size_mb = size_mb(data_train.data)\n",
    "\n",
    "AttributeError: 'TfidfVectorizer' object has no attribute 'get_feature_names_out'\n",
    "# Python program to demonstrate\n",
    "# basic array characteristics\n",
    "import numpy as np\n",
    " \n",
    "# Creating array object\n",
    "arr = np.array( [[ 1.5, 2.3, 3.6],[ 4, 2, 5]] )\n",
    " \n",
    "# Printing type of arr object\n",
    "print(\"Array is of type: \", type(arr))\n",
    " \n",
    "# Printing array dimensions (axes)\n",
    "print(\"No. of dimensions: \", arr.ndim)\n",
    " \n",
    "# Printing shape of array\n",
    "print(\"Shape of array: \", arr.shape)\n",
    " \n",
    "# Printing size (total number of elements) of array\n",
    "print(\"Size of array: \", arr.size)\n",
    " \n",
    "# Printing type of elements in array\n",
    "print(\"Array stores elements of type: \", arr.dtype)\n",
    "Array is of type:  <class 'numpy.ndarray'>\n",
    "No. of dimensions:  2\n",
    "Shape of array:  (2, 3)\n",
    "Size of array:  6\n",
    "Array stores elements of type:  float64\n",
    "# Python program to demonstrate\n",
    "# array creation techniques\n",
    "import numpy as np\n",
    " \n",
    "# Creating array from list with type float\n",
    "a = np.array([[1, 2, 4], [5, 8, 7]], dtype = 'float')\n",
    "print (\"Array created using passed list:\\n\", a)\n",
    " \n",
    "# Creating array from tuple\n",
    "b = np.array((1 , 3, 2))\n",
    "print (\"\\nArray created using passed tuple:\\n\", b)\n",
    " \n",
    "# Creating a 3X4 array with all zeros\n",
    "c = np.zeros((3, 4))\n",
    "print (\"\\nAn array initialized with all zeros:\\n\", c)\n",
    " \n",
    "# Create a constant value array of complex type\n",
    "d = np.full((3, 3), 6, dtype = 'complex')\n",
    "print (\"\\nAn array initialized with all 6s.\"\n",
    "            \"Array type is complex:\\n\", d)\n",
    " \n",
    "# Create an array with random values\n",
    "e = np.random.random((2, 2))\n",
    "print (\"\\nA random array:\\n\", e)\n",
    " \n",
    "# Create a sequence of integers\n",
    "# from 0 to 30 with steps of 5\n",
    "f = np.arange(0, 30, 5)\n",
    "print (\"\\nA sequential array with steps of 5:\\n\", f)\n",
    " \n",
    "# Create a sequence of 10 values in range 0 to 5\n",
    "g = np.linspace(0, 5, 10)\n",
    "print (\"\\nA sequential array with 10 values between\"\n",
    "                                        \"0 and 5:\\n\", g)\n",
    " \n",
    "# Reshaping 3X4 array to 2X2X3 array\n",
    "arr = np.array([[1, 2, 3, 4],\n",
    "                [5, 2, 4, 2],\n",
    "                [1, 2, 0, 1]])\n",
    " \n",
    "newarr = arr.reshape(2, 2, 3)\n",
    " \n",
    "print (\"\\nOriginal array:\\n\", arr)\n",
    "print (\"Reshaped array:\\n\", newarr)\n",
    " \n",
    "# Flatten array\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "flarr = arr.flatten()\n",
    " \n",
    "print (\"\\nOriginal array:\\n\", arr)\n",
    "print (\"Fattened array:\\n\", flarr)\n",
    "Array created using passed list:\n",
    " [[1. 2. 4.]\n",
    " [5. 8. 7.]]\n",
    "\n",
    "Array created using passed tuple:\n",
    " [1 3 2]\n",
    "\n",
    "An array initialized with all zeros:\n",
    " [[0. 0. 0. 0.]\n",
    " [0. 0. 0. 0.]\n",
    " [0. 0. 0. 0.]]\n",
    "\n",
    "An array initialized with all 6s.Array type is complex:\n",
    " [[6.+0.j 6.+0.j 6.+0.j]\n",
    " [6.+0.j 6.+0.j 6.+0.j]\n",
    " [6.+0.j 6.+0.j 6.+0.j]]\n",
    "\n",
    "A random array:\n",
    " [[0.89937539 0.64296692]\n",
    " [0.67560679 0.5219163 ]]\n",
    "\n",
    "A sequential array with steps of 5:\n",
    " [ 0  5 10 15 20 25]\n",
    "\n",
    "A sequential array with 10 values between0 and 5:\n",
    " [0.         0.55555556 1.11111111 1.66666667 2.22222222 2.77777778\n",
    " 3.33333333 3.88888889 4.44444444 5.        ]\n",
    "\n",
    "Original array:\n",
    " [[1 2 3 4]\n",
    " [5 2 4 2]\n",
    " [1 2 0 1]]\n",
    "Reshaped array:\n",
    " [[[1 2 3]\n",
    "  [4 5 2]]\n",
    "\n",
    " [[4 2 1]\n",
    "  [2 0 1]]]\n",
    "\n",
    "Original array:\n",
    " [[1 2 3]\n",
    " [4 5 6]]\n",
    "Fattened array:\n",
    " [1 2 3 4 5 6]\n",
    "l1=[1,2]\n",
    "l2=[3,4]    \n",
    "l3=l1+l2\n",
    "print(l3)\n",
    "[1, 2, 3, 4]\n",
    "# Python program to demonstrate\n",
    "# unary operators in numpy\n",
    "import numpy as np\n",
    " \n",
    "arr = np.array([[1, 5, 6],\n",
    "                [4, 7, 2],\n",
    "                [3, 1, 9]])\n",
    "print(arr)\n",
    "# maximum element of array\n",
    "print (\"Largest element is:\", arr.max())\n",
    "print (\"Row-wise maximum elements:\",\n",
    "                    arr.max(axis = 1))\n",
    " \n",
    "# minimum element of array\n",
    "print (\"Column-wise minimum elements:\",\n",
    "                        arr.min(axis = 0))\n",
    " \n",
    "# sum of array elements\n",
    "print (\"Sum of all array elements:\",\n",
    "                            arr.sum())\n",
    " \n",
    "# cumulative sum along each row\n",
    "print (\"Cumulative sum along each row:\\n\",\n",
    "                        arr.cumsum(axis = 1))\n",
    "[[1 5 6]\n",
    " [4 7 2]\n",
    " [3 1 9]]\n",
    "Largest element is: 9\n",
    "Row-wise maximum elements: [6 7 9]\n",
    "Column-wise minimum elements: [1 1 2]\n",
    "Sum of all array elements: 38\n",
    "Cumulative sum along each row:\n",
    " [[ 1  6 12]\n",
    " [ 4 11 13]\n",
    " [ 3  4 13]]\n",
    "# Python program to demonstrate\n",
    "# basic operations on single array\n",
    "import numpy as np\n",
    " \n",
    "a = np.array([1, 2, 5, 3])\n",
    "print(a)\n",
    "# add 1 to every element\n",
    "print (\"Adding 1 to every element:\", a+1)\n",
    " \n",
    "# subtract 3 from each element\n",
    "print (\"Subtracting 3 from each element:\", a-3)\n",
    " \n",
    "# multiply each element by 10\n",
    "print (\"Multiplying each element by 10:\", a*10)\n",
    " \n",
    "# square each element\n",
    "print (\"Squaring each element:\", a**2)\n",
    " \n",
    "# modify existing array\n",
    "a *= 2\n",
    "print (\"Doubled each element of original array:\", a)\n",
    " \n",
    "# transpose of array\n",
    "a = np.array([[1, 2, 3], [3, 4, 5], [9, 6, 0]])\n",
    " \n",
    "print (\"\\nOriginal array:\\n\", a)\n",
    "print (\"Transpose of array:\\n\", a.T)\n",
    "[1 2 5 3]\n",
    "Adding 1 to every element: [2 3 6 4]\n",
    "Subtracting 3 from each element: [-2 -1  2  0]\n",
    "Multiplying each element by 10: [10 20 50 30]\n",
    "Squaring each element: [ 1  4 25  9]\n",
    "Doubled each element of original array: [ 2  4 10  6]\n",
    "\n",
    "Original array:\n",
    " [[1 2 3]\n",
    " [3 4 5]\n",
    " [9 6 0]]\n",
    "Transpose of array:\n",
    " [[1 3 9]\n",
    " [2 4 6]\n",
    " [3 5 0]]\n",
    "# Python program to demonstrate\n",
    "# binary operators in Numpy\n",
    "import numpy as np\n",
    " \n",
    "a = np.array([[1, 2],\n",
    "            [3, 4]])\n",
    "b = np.array([[4, 3],\n",
    "            [2, 1]])\n",
    " \n",
    "# add arrays\n",
    "print (\"Array sum:\\n\", a + b)\n",
    " \n",
    "# multiply arrays (elementwise multiplication)\n",
    "print (\"Array multiplication:\\n\", a*b)\n",
    " \n",
    "# matrix multiplication\n",
    "print (\"Matrix multiplication:\\n\", a.dot(b))\n",
    "Array sum:\n",
    " [[5 5]\n",
    " [5 5]]\n",
    "Array multiplication:\n",
    " [[4 6]\n",
    " [6 4]]\n",
    "Matrix multiplication:\n",
    " [[ 8  5]\n",
    " [20 13]]\n",
    "# Python program to demonstrate\n",
    "# universal functions in numpy\n",
    "import numpy as np\n",
    " \n",
    "# create an array of sine values\n",
    "a = np.array([0, np.pi/2, np.pi])\n",
    "print (\"Sine values of array elements:\", np.sin(a))\n",
    " \n",
    "# exponential values\n",
    "a = np.array([0, 1, 2, 3])\n",
    "print (\"Exponent of array elements:\", np.exp(a))\n",
    " \n",
    "# square root of array values\n",
    "print (\"Square root of array elements:\", np.sqrt(a))\n",
    "Sine values of array elements: [ 0.00000000e+00  1.63312394e+16 -1.22464680e-16]\n",
    "Exponent of array elements: [ 1.          2.71828183  7.3890561  20.08553692]\n",
    "Square root of array elements: [0.         1.         1.41421356 1.73205081]\n",
    "# Python program to demonstrate sorting in numpy\n",
    "import numpy as np\n",
    " \n",
    "a = np.array([[1, 4, 2],\n",
    "                 [3, 4, 6],\n",
    "              [0, -1, 5]])\n",
    "print(a)\n",
    "# sorted array\n",
    "print (\"Array elements in sorted order:\\n\",\n",
    "                    np.sort(a, axis = None))\n",
    " \n",
    "# sort array row-wise\n",
    "print (\"Row-wise sorted array:\\n\",\n",
    "                np.sort(a, axis = 1))\n",
    " \n",
    "# specify sort algorithm\n",
    "print (\"Column wise sort by applying merge-sort:\\n\",\n",
    "            np.sort(a, axis = 0, kind = 'mergesort'))\n",
    " \n",
    "# Example to show sorting of structured array\n",
    "# set alias names for dtypes\n",
    "dtypes = [('name', 'S10'), ('grad_year', int), ('cgpa', float)]\n",
    " \n",
    "# Values to be put in array\n",
    "values = [('Hrithik', 2009, 8.5), ('Ajay', 2008, 8.7),\n",
    "           ('Pankaj', 2008, 7.9), ('Aakash', 2009, 9.0)]\n",
    "            \n",
    "# Creating array\n",
    "arr = np.array(values, dtype = dtypes)\n",
    "print (\"\\nArray sorted by names:\\n\",\n",
    "            np.sort(arr, order = 'name'))\n",
    "             \n",
    "print (\"Array sorted by graduation year and then cgpa:\\n\",\n",
    "                np.sort(arr, order = ['grad_year', 'cgpa']))\n",
    "[[ 1  4  2]\n",
    " [ 3  4  6]\n",
    " [ 0 -1  5]]\n",
    "Array elements in sorted order:\n",
    " [-1  0  1  2  3  4  4  5  6]\n",
    "Row-wise sorted array:\n",
    " [[ 1  2  4]\n",
    " [ 3  4  6]\n",
    " [-1  0  5]]\n",
    "Column wise sort by applying merge-sort:\n",
    " [[ 0 -1  2]\n",
    " [ 1  4  5]\n",
    " [ 3  4  6]]\n",
    "\n",
    "Array sorted by names:\n",
    " [(b'Aakash', 2009, 9. ) (b'Ajay', 2008, 8.7) (b'Hrithik', 2009, 8.5)\n",
    " (b'Pankaj', 2008, 7.9)]\n",
    "Array sorted by graduation year and then cgpa:\n",
    " [(b'Pankaj', 2008, 7.9) (b'Ajay', 2008, 8.7) (b'Hrithik', 2009, 8.5)\n",
    " (b'Aakash', 2009, 9. )]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6347788ef9fb7b048935ed9bc09ccad6888b2dc72e72ac11c8d0cbe5a8d37d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
